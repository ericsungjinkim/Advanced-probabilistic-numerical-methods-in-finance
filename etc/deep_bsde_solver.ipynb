{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal as normal\n",
    "\n",
    "import time\n",
    "\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We define the Equation Class to generate the input data for training our NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Equation(object):\n",
    "    '''\n",
    "    This is the super class of the Equation.\n",
    "    We have two child class of Equation, HJBLQ and Efault_Risk.\n",
    "    Each class has their own parameter to generate sample for training a Deep NN\n",
    "    '''\n",
    "    def __init__(self,eqn_config):\n",
    "        self.dim = eqn_config[\"dim\"]\n",
    "        self.total_time = eqn_config[\"total_time\"]\n",
    "        self.num_time_interval = eqn_config[\"num_time_interval\"]\n",
    "        self.delta_t = self.total_time / self.num_time_interval\n",
    "        self.sqrt_delta_t = np.sqrt(self.delta_t)\n",
    "        self.y_init = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Hamilton-Jacobi-Bellman (HJB) Equation\n",
    "We consider a classical linear-quadratic-Gaussian (LQG) control problem in 100 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HJB(Equation):\n",
    "    '''\n",
    "    We use the setting of the paper J. Han \"Solving High-Dimensional Partial\n",
    "    Differential Equations Using Deep Learning\"\n",
    "    '''\n",
    "    def __init__(self, eqn_config):\n",
    "        super(HJB, self).__init__(eqn_config)\n",
    "        self.x_init = np.zeros(self.dim)\n",
    "        self.sigma = np.sqrt(2.0)\n",
    "        self.lambd = 1.0\n",
    "\n",
    "    def sample(self, num_sample):\n",
    "        dw_sample = normal.rvs(size=[num_sample,\n",
    "                                     self.dim,\n",
    "                                     self.num_time_interval]) * self.sqrt_delta_t\n",
    "        x_sample = np.zeros([num_sample, self.dim, self.num_time_interval + 1])\n",
    "        x_sample[:, :, 0] = np.ones([num_sample, self.dim]) * self.x_init\n",
    "        for i in range(self.num_time_interval):\n",
    "            x_sample[:, :, i + 1] = x_sample[:, :, i] + self.sigma * dw_sample[:, :, i]\n",
    "        return dw_sample, x_sample\n",
    "\n",
    "    def f_tf(self, t, x, y, z):\n",
    "        # To calculate f term in (5) equation of the article of \"solving High-Dimensional Partial Differential Equation Using Deep Learning\"\n",
    "        return -self.lambd * torch.mul(z, z).sum(1)\n",
    "\n",
    "    def g_tf(self, t, x):\n",
    "        return torch.log((1 + torch.mul(x, x).sum(1)) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Nonlinear Black-Scholes Equation with Default Risk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Default_Risk(Equation):\n",
    "    '''\n",
    "    We use the setting of the paper J. Han \"Solving High-Dimensional Partial\n",
    "    Differential Equations Using Deep Learning\"\n",
    "    '''\n",
    "    def __init__(self, eqn_config):\n",
    "        super(Default_Risk, self).__init__(eqn_config)\n",
    "        self.x_init = np.ones(self.dim) * 100.0\n",
    "        self.sigma = 0.2\n",
    "        self.rate = 0.02   # interest rate R\n",
    "        self.delta = 2.0 / 3\n",
    "        self.gammah = 0.2\n",
    "        self.gammal = 0.02\n",
    "        self.mu_bar = 0.02\n",
    "        self.vh = 50.0\n",
    "        self.vl = 70.0\n",
    "        self.slope = (self.gammah - self.gammal) / (self.vh - self.vl)\n",
    "\n",
    "    def sample(self, num_sample):\n",
    "        dw_sample = normal.rvs(size=[num_sample,self.dim,self.num_time_interval])*self.sqrt_delta_t\n",
    "        x_sample = np.zeros([num_sample,self.dim,self.num_time_interval+1])\n",
    "        x_sample[:, :, 0] = np.ones([num_sample, self.dim]) * self.x_init\n",
    "\n",
    "        for t in range(self.num_time_interval):\n",
    "            # (5) equation in the article of \"solving High-Dimensional Partial Differential Equation Using Deep Learning\"\n",
    "            x_sample[:,:,t+1] = (1+self.mu_bar*self.delta_t)*x_sample[:,:,t]+(self.sigma*x_sample[:,:,t]*dw_sample[:,:,t])\n",
    "\n",
    "        return dw_sample, x_sample\n",
    "\n",
    "    def f_tf(self, t, x, y, z):\n",
    "        # To calculate f term in (5) equation of the article of \"solving High-Dimensional Partial Differential Equation Using Deep Learning\"\n",
    "        m = torch.nn.ReLU()\n",
    "        piecewise_linear = m(m(y - self.vh) * self.slope + self.gammah - self.gammal) + self.gammal\n",
    "        return (-(1 - self.delta) * piecewise_linear - self.rate) * y\n",
    "\n",
    "    def g_tf(self, t, x):\n",
    "        batch_size = x.size()[0]\n",
    "        return  x.min(1).values.reshape([batch_size,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BSDE Neural Network Architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BSDE_solver(object):\n",
    "    def __init__(self,config, eqn):\n",
    "        self.eqn_config = config[\"eqn_config\"]\n",
    "        self.net_config = config[\"net_config\"]\n",
    "        self.eqn = eqn\n",
    "\n",
    "        self.model = BSDE_NN(config,eqn)\n",
    "        self.y_init = self.model.y_init\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(),lr=self.net_config[\"lr_value\"],eps=1e-8)\n",
    "\n",
    "    def train(self):\n",
    "        start_time = time.time()\n",
    "        valid_data = self.eqn.sample(self.net_config[\"valid_size\"])\n",
    "\n",
    "        # We use the same input data for just validation each 100 epochs.\n",
    "        validation_history = []\n",
    "        training_history = []\n",
    "        for step in range(self.net_config[\"num_iterations\"]+1):\n",
    "            # (8) equation in the article \"solving High-Dimensional Partial Differential Equation Using Deep Learning\"\n",
    "            loss = torch.nn.MSELoss()\n",
    "\n",
    "            if step % 100 == 0 :\n",
    "                inputs = valid_data\n",
    "                training = False\n",
    "\n",
    "            else:\n",
    "                # During training, we generate the new input data\n",
    "                inputs = self.eqn.sample(self.net_config[\"batch_size\"])\n",
    "                training = True\n",
    "\n",
    "            batch_size = inputs[0].shape[0]\n",
    "            y_terminal_model = self.model(inputs,training)\n",
    "\n",
    "            y_terminal_target = self.eqn.g_tf(self.eqn.total_time, torch.tensor(inputs[1][:,:,-1], dtype=dtype)).reshape([batch_size,1])\n",
    "            loss_val = loss(y_terminal_model,y_terminal_target)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            err_rate = (loss_val.item() / y_terminal_target.mean()).item()\n",
    "            y_init = self.model.y_init.data.item()\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                training_time = time.time() - start_time\n",
    "                validation_history.append([step, err_rate, y_init,training_time])\n",
    "                print(\"step: {},  err_rate: {:.5f},  Y0: {:.5f}, Traing_time: {:.5f}\".format(step,err_rate,y_init,training_time))\n",
    "\n",
    "            training_history.append([step, err_rate, y_init])\n",
    "\n",
    "        return training_history\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We set our model. Network is same as in the article. We train all the parameters of NN and initial value of $u(0,X_0)$ and $Z_0 = \\sigma^T(t_0,X_0)\\nabla u(t_0,X_{t_0})$. We set the initial value as a parameters for training\n",
    "\n",
    "Each sub network calculate $\\sigma^T(t_n,X_{t_n})\\nabla u(t_n,X_{t_n})$.\n",
    "\n",
    "We set $z = \\sigma^T(t_n,X_{t_n})\\nabla u(t_n,X_{t_n})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BSDE_NN(torch.nn.Module):\n",
    "    def __init__(self,config, eqn):\n",
    "        super(BSDE_NN,self).__init__()\n",
    "        self.eqn_config = config[\"eqn_config\"]\n",
    "        self.net_config = config[\"net_config\"]\n",
    "        self.eqn = eqn\n",
    "\n",
    "        # Set all initial values as a parameter for training\n",
    "        y_init = torch.tensor(np.random.uniform(low=self.net_config[\"y_init_range\"][0],\n",
    "                                                high=self.net_config[\"y_init_range\"][1],\n",
    "                                                size=[1]),\n",
    "                              dtype=dtype, requires_grad=True)\n",
    "        self.y_init = torch.nn.Parameter(y_init)\n",
    "\n",
    "        z_init = torch.tensor(np.random.uniform(low=-.1,high=.1,\n",
    "                                                size=[1,self.eqn_config[\"dim\"]]),\n",
    "                              dtype=dtype, requires_grad=True)\n",
    "        self.z_init = torch.nn.Parameter(z_init)\n",
    "\n",
    "        # Set the sub-network for calculating the gradient of u of each time.\n",
    "        # Each sub-network is multilayer feedforward neural network approximation the product of sigma * gradients of u at time t = t_n\n",
    "        self.subnet = torch.nn.ModuleList(\n",
    "            [Feedforward_NN(config) for _ in range(self.eqn_config[\"num_time_interval\"]-1)])\n",
    "\n",
    "    def forward(self, inputs, training):\n",
    "        batch_size = inputs[0].shape[0]\n",
    "        dw = torch.tensor(inputs[0],dtype=dtype)\n",
    "        x = torch.tensor(inputs[1],dtype=dtype)\n",
    "\n",
    "        time_stamp = np.arange(0,self.eqn_config[\"num_time_interval\"]) * self.eqn.delta_t\n",
    "        all_one_vector = torch.ones(batch_size,1,dtype=dtype)\n",
    "\n",
    "        # y is the value of u(t,x)\n",
    "        # the first setting of y is u(0,x_0). We fix the x_0 from equation class\n",
    "        y = all_one_vector * self.y_init\n",
    "        z = all_one_vector.mm(self.z_init)\n",
    "\n",
    "        for t in range(0, self.eqn.num_time_interval -1):\n",
    "            # (5) equation of the article of \"solving High-Dimensional Partial Differential Equation Using Deep Learning\"\n",
    "            y = y - (self.eqn.delta_t * (self.eqn.f_tf(time_stamp[t], x[:, :, t], y, z).reshape([batch_size,1])) + \\\n",
    "                     (torch.mm(z, dw[:, :, t].t()).sum(1)).reshape([batch_size,1])).reshape([batch_size,1])\n",
    "            # Calculate the product of sigma * gradients of u at time t = t_n\n",
    "            z = self.subnet[t](x[:, :, t + 1], training) / self.eqn.dim\n",
    "\n",
    "        # Terminal u(t_N,x)\n",
    "        y = y - (self.eqn.delta_t * (self.eqn.f_tf(time_stamp[t], x[:, :, t], y, z).reshape([batch_size,1])) + \\\n",
    "                     (torch.mm(z, dw[:, :, t].t()).sum(1)).reshape([batch_size,1])).reshape([batch_size,1])\n",
    "        y = y.reshape([batch_size,1])\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Feedforward_NN(torch.nn.Module):\n",
    "    '''\n",
    "    This is the NN for the feedforward to calculate the gradient of u at t = t_n\n",
    "    '''\n",
    "    def __init__(self,config):\n",
    "        super(Feedforward_NN, self).__init__()\n",
    "        dim = config[\"eqn_config\"][\"dim\"]\n",
    "        num_hiddens = config[\"net_config\"][\"num_hiddens\"]\n",
    "\n",
    "        # batchnormal layer for the input data\n",
    "        self.batchnormal_layers = torch.nn.ModuleList([torch.nn.BatchNorm1d(dim, momentum=0.99, eps=1e-6, affine=True)])\n",
    "        for i in num_hiddens:\n",
    "            # batchnormal layer for the each hidden layer\n",
    "            self.batchnormal_layers.append(torch.nn.BatchNorm1d(i, momentum=0.99, eps=1e-6, affine=True))\n",
    "        # batchnormal layer for the output data\n",
    "        self.batchnormal_layers.append(torch.nn.BatchNorm1d(dim, momentum=0.99, eps=1e-6, affine=True))\n",
    "\n",
    "        # Linear layer from input to first hiden layer\n",
    "        self.dense_layers = torch.nn.ModuleList([torch.nn.Linear(dim, num_hiddens[0], bias=False)])\n",
    "        for i in range(len(num_hiddens) - 1):\n",
    "            # Linear layer from i hidden layer to i+1 hidden layer\n",
    "            self.dense_layers.append(torch.nn.Linear(num_hiddens[i], num_hiddens[i + 1], bias=False))\n",
    "        # Linear layer from last hidden layer to output\n",
    "        self.dense_layers.append(torch.nn.Linear(num_hiddens[-1], dim, bias=False))\n",
    "\n",
    "    def forward(self,x,training):\n",
    "        x = self.batchnormal_layers[0](x)\n",
    "        for i in range(len(self.dense_layers) - 1):\n",
    "            x = self.dense_layers[i](x)\n",
    "            x = self.batchnormal_layers[i + 1](x)\n",
    "            x = F.relu(x)\n",
    "        x = self.dense_layers[-1](x)\n",
    "        x = self.batchnormal_layers[-1](x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "HJB_config = {\n",
    "  \"eqn_config\": {\n",
    "    \"total_time\": 1.0,\n",
    "    \"dim\": 100,\n",
    "    \"num_time_interval\": 20,\n",
    "  },\n",
    "  \"net_config\": {\n",
    "    \"y_init_range\": [4, 5],\n",
    "    \"num_hiddens\": [110, 110],\n",
    "    \"lr_value\": 1e-2,\n",
    "    \"num_iterations\": 2000,\n",
    "    \"batch_size\": 64,\n",
    "    \"valid_size\": 256,\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Default_Risk_config = {\n",
    "  \"eqn_config\": {\n",
    "    \"total_time\": 1.0,\n",
    "    \"dim\": 100,\n",
    "    \"num_time_interval\": 40\n",
    "  },\n",
    "  \"net_config\": {\n",
    "    \"y_init_range\": [40, 50],\n",
    "    \"num_hiddens\": [110, 110],\n",
    "    \"lr_value\": 8e-3,\n",
    "    \"num_iterations\": 4000,\n",
    "    \"batch_size\": 64,\n",
    "    \"valid_size\": 256,\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "HJB_eqn = HJB(HJB_config[\"eqn_config\"])\n",
    "HJB_solver = BSDE_solver(HJB_config,HJB_eqn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0,  err_rate: 1.67120,  Y0: 0.40243, Traing_time: 0.21786\n",
      "step: 100,  err_rate: 4.72231,  Y0: 0.87296, Traing_time: 10.89423\n",
      "step: 200,  err_rate: 3.92080,  Y0: 1.29625, Traing_time: 20.71011\n"
     ]
    }
   ],
   "source": [
    "training_history = HJB_solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}